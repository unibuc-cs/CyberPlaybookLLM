{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This is a dataset generator and validator for the MITRE ATT&CK framework using OpenAI's API models.",
   "id": "d5e3396aff64db08"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T15:25:47.838432Z",
     "start_time": "2025-04-17T15:25:47.289442Z"
    }
   },
   "source": [
    "from distutils.command.clean import clean\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "from scipy.io.arff.tests.test_arffread import missing\n",
    "from tqdm.auto import tqdm\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load from .env file\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_key\n",
    "\n",
    "default_model_name =  \"GPT-4o mini\" #\"gpt-4-turbo\"\n",
    "\n",
    "MITRE_TECHNIQUES_DEMO = [\n",
    "    (\"T1566.001\", \"Phishing: Spearphishing Attachment\"),\n",
    "    (\"T1203\", \"Exploitation for Client Execution\"),\n",
    "    (\"T1486\", \"Data Encrypted for Impact\"),\n",
    "    (\"T1021.001\", \"Remote Desktop Protocol\"),\n",
    "    (\"T1003.001\", \"OS Credential Dumping\"),\n",
    "    (\"T1059.003\", \"Windows Command Shell\"),\n",
    "    (\"T1071.001\", \"Application Layer Protocol: Web Protocols\"),\n",
    "    (\"T1053.005\", \"Scheduled Task/Job: Scheduled Task\"),\n",
    "    (\"T1218.010\", \"Signed Binary Proxy Execution: Regsvr32\"),\n",
    "    (\"T1490\", \"Inhibit System Recovery\"),\n",
    "    # Add more as needed\n",
    "]\n",
    "\n",
    "#MITRE_TECHNIQUES = MITRE_TECHNIQUES_DEMO\n",
    "\n",
    "# Load the MITRE techniques from the JSON file, we use the distributed ones\n",
    "with open(\"Samples/mitre_techniques_distributed.json\", \"r\") as f:\n",
    "    MITRE_TECHNIQUES = json.load(f)\n",
    "\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:49:25.744103Z",
     "start_time": "2025-04-17T15:49:25.740547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#def generate_incident(technique_tuple):\n",
    "from pprint import pprint\n",
    "# Given a tuple (technique_id, technique_desc), generate a realistic incident scenario using OpenAI's API and a given model.\n",
    "# Returns the generated incident in JSON format.\n",
    "def generate_incident(technique_tuple, model_name=\"gpt-4-turbo\"):\n",
    "    technique_id, technique_desc = technique_tuple\n",
    "    # prompt_old = f\"\"\"\n",
    "    # Your are an expert in cybersecurity.\n",
    "    # Generate a realistic cybersecurity incident scenario aligned with MITRE ATT&CK technique {technique_id}: {technique_desc}.\n",
    "    #\n",
    "    # Clearly provide:\n",
    "    # - A short incident description.\n",
    "    # - A chronological set of 3-5 structured attack logs with timestamps and actions.\n",
    "    # - 3 to 5 clearly structured ground-truth mitigations steps as you would do in a real incident response.\n",
    "    #\n",
    "    # Format your output exactly as JSON:\n",
    "    # {{\n",
    "    #   \"incident_id\": \"{uuid.uuid4()}\",\n",
    "    #   \"technique_id\": \"{technique_id}\",\n",
    "    #   \"technique_desc\": \"{technique_desc}\",\n",
    "    #   \"incident_description\": \"...\",\n",
    "    #   \"attack_logs\": [{{\"timestamp\":\"...\", \"host\":\"...\", \"action\":\"...\", \"details\":\"...\"}}, ...],\n",
    "    #   \"ground_truth_mitigations\": [\"step1\", \"step2\", \"...\"]\n",
    "    # }}\n",
    "    # \"\"\"\n",
    "\n",
    "\n",
    "    incident_prompt_template = f\"\"\"\n",
    "    You are a cybersecurity simulation assistant trained to generate structured synthetic incident data for automation workflows.\n",
    "\n",
    "    Your task is to generate a JSON object representing a cybersecurity incident that is aligned with a given MITRE ATT&CK technique which is described in the following link: https://attack.mitre.org/techniques/{technique_id}/\n",
    "\n",
    "    The JSON must include the following fields:\n",
    "\n",
    "    1. `incident_id` – a unique identifier (UUID format).\n",
    "    2. `technique_id` – e.g., T1059\n",
    "    3. `technique_desc` – short description of the MITRE technique (e.g., Command and Scripting Interpreter).\n",
    "    4. `incident_description` – a 2-sentence narrative of how the attack unfolded.\n",
    "    5. `attack_logs` – a list of exactly 3 logs, each containing:\n",
    "       - `timestamp` (ISO 8601 format)\n",
    "       - `host` (e.g., host-22)\n",
    "       - `action` (e.g., “File Dropped”)\n",
    "       - `details` (e.g., suspicious behavior)\n",
    "    6. `ground_truth_mitigations` – a list of 3 to 6 mitigation steps. Each mitigation should include:\n",
    "       - `step`: description of the action (e.g., “Kill malicious process”)\n",
    "       - `uuid`: a unique UUID\n",
    "       - `agent`: organization ID responsible (e.g., organization--abc)\n",
    "       - `command`: executable bash-style command to perform the step\n",
    "       - optionally:\n",
    "         - `condition`: for if/else branching\n",
    "         - `loop`: for iterative steps\n",
    "         - `variables`: any variable set or used\n",
    "\n",
    "    You are encouraged to add structural diversity:\n",
    "    - Some mitigations should include loop or conditional logic (e.g., “repeat until scan is clean”).\n",
    "    - Some should be parallelizable or dependent on others using variable links.\n",
    "\n",
    "    The final output must be valid JSON.\n",
    "    Only return the JSON object.\n",
    "\n",
    "    Target MITRE Technique:\n",
    "    {technique_id} - {technique_desc}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": incident_prompt_template}],\n",
    "        #temperature=0.6,\n",
    "        #max_tokens=4096,\n",
    "    )\n",
    "\n",
    "    output_json_str = response.choices[0].message.content\n",
    "    match = re.search(r'\\{.*\\}', output_json_str, re.DOTALL)\n",
    "\n",
    "    clean_json_str = None # This is the string that will be parsed\n",
    "    clean_json = None # This is the json that will be returned (dict format, not a string)\n",
    "    if match:\n",
    "        clean_json_str = match.group(0)\n",
    "        clean_json = json.loads(clean_json_str)\n",
    "\n",
    "        #pprint(clean_json)\n",
    "    else:\n",
    "        print(\"No JSON-like structure found in the response.\")\n",
    "        clean_json = output_json_str\n",
    "\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "    key = f\"{technique_id}_{timestamp}\"\n",
    "    return {key: clean_json}\n",
    "\n",
    "\n"
   ],
   "id": "9839d97bac870574",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:49:17.609028Z",
     "start_time": "2025-04-17T15:49:17.587358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Take by round robin the techniques from the list and generate incidents\n",
    "models_to_try = [\"gpt-4o\"] #[\"gpt-4o-mini\"]# [\"o3\", \"o3-mini\", \"gpt-4o\", \"gpt-4.5-preview\"] #[\"gpt-4o-mini\"] #[\"o3-mini\"] #[\"gpt-4o-mini\", \"o3-mini\"]#[\"gpt-4o\", \"gpt-4.5-preview\"] #\"gpt-4o-mini\", \"gpt-4-turbo\", o mini\", \"GPT-4o\", \"gpt-3.5-turbo\", \"o3-mini\", \"o3\", \"gpt-4\"]\n",
    "\n",
    "NUM_SAMPLES_PER_TECHNIQUE = 1\n",
    "DEMO_MODE = True\n",
    "\n",
    "LIMIT = NUM_SAMPLES_PER_TECHNIQUE * len(MITRE_TECHNIQUES) if not DEMO_MODE else 30\n",
    "\n",
    "# Iterate over the models\n",
    "for model_iter in tqdm(models_to_try, desc=\"Models\", total=len(models_to_try), leave=False):\n",
    "    # For each model, iterate over the techniques\n",
    "    model_outputs = []\n",
    "    round_robin_counter = 0\n",
    "\n",
    "    with tqdm(total=NUM_SAMPLES_PER_TECHNIQUE, desc=\"Round robin iteration\", leave=False) as pbar:\n",
    "        while len(model_outputs) < LIMIT:\n",
    "            round_robin_counter += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Randomly shuffle the techniques\n",
    "            techniques  = MITRE_TECHNIQUES\n",
    "            random.shuffle(MITRE_TECHNIQUES)\n",
    "\n",
    "            # Wrap tqdm ONCE for this batch\n",
    "            technique_iterator = tqdm(techniques, desc=\"Techniques\", total=len(techniques), leave=False)\n",
    "\n",
    "            for technique_tuple in technique_iterator:\n",
    "                # For each technique, generate an incident\n",
    "                try:\n",
    "                    response = generate_incident(technique_tuple, model_name=model_iter)\n",
    "                    # THe response is a dictionary with the techniqueid_timestamp as key and the incident as value\n",
    "                    if response:\n",
    "                        # Add the response to the model outputs\n",
    "                        model_outputs.append(response)\n",
    "\n",
    "                        if len(model_outputs) >= LIMIT:\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating incident for model {model_iter} and technique {technique_tuple}: {e}\")\n",
    "\n",
    "    # Save the generated incident to a JSON file\n",
    "    model_output_folder = f\"Samples/{model_iter}\"\n",
    "    os.makedirs(model_output_folder, exist_ok=True)\n",
    "    # Append the response to a JSON file\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(f\"{model_output_folder}/dataset.json\"):\n",
    "        # If it exists, load the existing data\n",
    "        with open(f\"{model_output_folder}/dataset.json\", \"r\") as f:\n",
    "            existing_data = json.load(f)\n",
    "            # Append the new data to the existing data\n",
    "            existing_data.extend(model_outputs)\n",
    "            model_outputs = existing_data\n",
    "    with open(f\"{model_output_folder}/dataset.json\", \"w\") as f:\n",
    "        json.dump(model_outputs, f, indent=4)\n",
    "\n"
   ],
   "id": "9085024767d446f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Round robin iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "                                                            \u001B[A\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MITRE_TECHNIQUES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     23\u001B[39m pbar.update(\u001B[32m1\u001B[39m)\n\u001B[32m     25\u001B[39m \u001B[38;5;66;03m# Randomly shuffle the techniques\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m techniques  = \u001B[43mMITRE_TECHNIQUES\u001B[49m\n\u001B[32m     27\u001B[39m random.shuffle(MITRE_TECHNIQUES)\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# Wrap tqdm ONCE for this batch\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'MITRE_TECHNIQUES' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:06:44.277696Z",
     "start_time": "2025-04-09T15:06:44.274762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(model_outputs))\n",
    "# # Save the generated incident to a JSON file\n",
    "# model_output_folder = f\"Samples/{models_to_try[0]}\"\n",
    "# os.makedirs(model_output_folder, exist_ok=True)\n",
    "# # Append the response to a JSON file\n",
    "# # Check if the file already exists\n",
    "# if os.path.exists(f\"{model_output_folder}/dataset.json\"):\n",
    "#     # If it exists, load the existing data\n",
    "#     with open(f\"{model_output_folder}/dataset.json\", \"r\") as f:\n",
    "#         existing_data = json.load(f)\n",
    "#         # Append the new data to the existing data\n",
    "#         existing_data.extend(model_outputs)\n",
    "#         model_outputs = existing_data\n",
    "# with open(f\"{model_output_folder}/dataset.json\", \"w\") as f:\n",
    "#     json.dump(model_outputs, f, indent=4)"
   ],
   "id": "b8a8d0b9ded2e209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
